{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e5fc3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e1aa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in full data files\n",
    "gene_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b39e76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "# For testing set\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b99a492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded object is a list of models. n_models: 16101\n",
      "y_pred.shape: (3187, 16101)\n",
      "model.n_features_in_: None\n",
      "model.n_outputs_: None\n",
      "x_test.shape: (3187, 1198)\n",
      "y_test.shape: (3187, 16101)\n",
      "Multi-output R^2 (uniform_average): 0.7601639389405871\n"
     ]
    }
   ],
   "source": [
    "# Load model in with pickle file \n",
    "\n",
    "with open('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/Random Forest/RF_model.pkl', 'rb') as file:\n",
    "    loaded = pickle.load(file)\n",
    "    \n",
    "# Evaluate model \n",
    "\n",
    "# If you saved a list of estimators (one per gene) build predictions matrix\n",
    "\n",
    "if isinstance(loaded, list):\n",
    "    models = loaded\n",
    "    print(\"Loaded object is a list of models. n_models:\", len(models))\n",
    "    y_pred = np.column_stack([m.predict(x_test) for m in models])  # (n_samples, n_genes)\n",
    "else:\n",
    "    model = loaded\n",
    "    print(\"Loaded object type:\", type(model))\n",
    "    # If single-output model but y_test is multi-column, this will raise -- handled later\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "# diagnostics (safe access)\n",
    "def safe_attr(obj, name):\n",
    "    return getattr(obj, name, None) if not isinstance(obj, list) else None\n",
    "\n",
    "print(\"model.n_features_in_:\", safe_attr(loaded, \"n_features_in_\"))\n",
    "print(\"model.n_outputs_:\", safe_attr(loaded, \"n_outputs_\"))\n",
    "print(\"x_test.shape:\", x_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "# Continue with your R^2 / MSE logic expecting y_pred shape (n_samples, n_targets)\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# If y_pred is 1D, treat as single-output\n",
    "if y_pred.ndim == 1 or (y_pred.ndim == 2 and y_pred.shape[1] == 1):\n",
    "    if y_test.ndim == 2 and y_test.shape[1] > 1:\n",
    "        raise ValueError(\n",
    "            \"Model predicts a single target but y_test contains multiple targets (genes).\\n\"\n",
    "            \"Select the trained target column before splitting, e.g.:\\n\"\n",
    "            \"  target = 'GENE_NAME'\\n\"\n",
    "            \"  y = gene_expression[target]\\n\"\n",
    "            \"  then redo train_test_split and evaluation.\"\n",
    "        )\n",
    "    y_true = y_test.ravel()\n",
    "    print(\"R^2:\", r2_score(y_true, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
    "else:\n",
    "    print(\"Multi-output R^2 (uniform_average):\", r2_score(y_test, y_pred, multioutput='uniform_average'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4b712da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first estimator type: <class 'xgboost.sklearn.XGBRFRegressor'>\n",
      "n_features_in_: 1198\n",
      "example feature_importances_ (first 10): [0.02488494 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "first = models[0]\n",
    "print(\"first estimator type:\", type(first))\n",
    "print(\"n_features_in_:\", getattr(first, \"n_features_in_\", None))\n",
    "print(\"example feature_importances_ (first 10):\", getattr(first, \"feature_importances_\", None)[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
