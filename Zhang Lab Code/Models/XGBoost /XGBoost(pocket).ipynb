{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "85eefdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap \n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torch as nn\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa2ae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in pocket data files\n",
    "gene_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Pocket data files/Geneexpression(pocket).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Pocket data files/TF(pocket).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4d4162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "# For testing set\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5248a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e2523068f64a62af73d611b38e0d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training targets:   0%|           0/3960 [  0%]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_xgb = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    verbosity=1,\n",
    "    n_estimators=100,\n",
    ")\n",
    "\n",
    "models = []\n",
    "n_targets = y_train.shape[1]\n",
    "\n",
    "# progress bar showing percent complete of target-level training\n",
    "pbar = tqdm(range(n_targets), desc=\"Training targets\", unit=\"target\",\n",
    "            bar_format=\"{l_bar}{bar} {n_fmt}/{total_fmt} [{percentage:3.0f}%]\")\n",
    "\n",
    "for i in pbar:\n",
    "    est = xgb.XGBRegressor(objective='reg:squarederror',\n",
    "                           eval_metric='rmse', verbosity=1, n_estimators=100)\n",
    "    # turn off verbose printing so tqdm stays clean\n",
    "    est.fit(x_train, y_train[:, i], eval_set=[(x_val, y_val[:, i])], verbose=False)\n",
    "    models.append(est)\n",
    "    pbar.set_postfix({'target': i})\n",
    "\n",
    "predictions = np.column_stack([m.predict(x_test) for m in models])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101004b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "[[0.        0.        0.        ... 0.        1.93641   0.       ]\n",
      " [0.        0.        0.        ... 0.        1.7565801 0.       ]\n",
      " [2.7519422 0.        0.        ... 0.        1.2960573 0.       ]\n",
      " ...\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]\n",
      " [0.        2.9892867 0.        ... 3.9883952 0.        0.       ]\n",
      " [0.        0.        0.        ... 0.        0.        0.       ]]\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Checking training data integrity\n",
    "print(x_train.dtype)\n",
    "print(x_train)\n",
    "print(np.isnan(x_train).sum())  # Check for NaN values\n",
    "print(np.isinf(x_train).sum())  # Check for infinite values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c78c35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/Training/lib/python3.13/site-packages/xgboost/sklearn.py:1115: UserWarning: [19:28:20] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1762060257953/work/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "/opt/anaconda3/envs/Training/lib/python3.13/site-packages/xgboost/sklearn.py:1115: UserWarning: [19:28:21] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1762060257953/work/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n",
      "/opt/anaconda3/envs/Training/lib/python3.13/site-packages/xgboost/sklearn.py:1115: UserWarning: [19:28:22] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1762060257953/work/src/c_api/c_api.cc:1575: Saving model in the UBJSON format as default.  You can use a file extension: `json` or `ubj` to choose between formats.\n",
      "  self.get_booster().save_model(fname)\n"
     ]
    }
   ],
   "source": [
    "model_paths = []\n",
    "for i, model in enumerate(models):\n",
    "    model_path = f'/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/XGBoost/xgb_model_target_{i}.model'\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True) \n",
    "    model.save_model(model_path)\n",
    "    model_paths.append(model_path)\n",
    "\n",
    "# Save the paths to a summary file\n",
    "with open('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/XGBoost/model_paths.txt', 'w') as f:\n",
    "    for path in model_paths:\n",
    "        f.write(f\"{path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0713cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tempfile, os, re\n",
    "\n",
    "feature_names = tf_expression.columns.tolist()\n",
    "target_names = gene_expression.columns.tolist()\n",
    "\n",
    "shap_values_per_target = {}\n",
    "for i, model in enumerate(models):\n",
    "    booster = model.get_booster() if hasattr(model, \"get_booster\") else model\n",
    "\n",
    "    # save to JSON then normalize any stringified numeric params (e.g. base_score == \"[2.991465E-1]\")\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".json\")\n",
    "    tmp.close()\n",
    "    try:\n",
    "        booster.save_model(tmp.name)\n",
    "\n",
    "        # read JSON and replace base_score strings like \"[2.991465E-1]\" -> 0.2991465\n",
    "        s = open(tmp.name, \"r\", encoding=\"utf-8\").read()\n",
    "        pattern = r'\"base_score\"\\s*:\\s*\"\\[([0-9Ee\\+\\-\\.]+)\\]\"'\n",
    "        def _repl(m):\n",
    "            return f'\"base_score\": {float(m.group(1))}'\n",
    "        s2, n = re.subn(pattern, _repl, s)\n",
    "        if n > 0:\n",
    "            with open(tmp.name, \"w\", encoding=\"utf-8\") as fw:\n",
    "                fw.write(s2)\n",
    "\n",
    "        # reload normalized Booster\n",
    "        booster = xgb.Booster(model_file=tmp.name)\n",
    "    finally:\n",
    "        os.remove(tmp.name)\n",
    "\n",
    "    explainer = shap.TreeExplainer(booster)\n",
    "    sv = explainer.shap_values(x_train)  # (n_samples, n_features)\n",
    "    shap_values_per_target[target_names[i] if i < len(target_names) else f\"target_{i}\"] = pd.DataFrame(sv, columns=feature_names)\n",
    "\n",
    "# Combine into one table with MultiIndex columns (target, feature)\n",
    "shap_df = pd.concat(shap_values_per_target, axis=1)\n",
    "shap_df.to_csv('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/XGBoost/shap_values_table.csv', index=False)\n",
    "shap_df.head()\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
