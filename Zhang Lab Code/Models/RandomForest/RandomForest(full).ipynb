{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc533c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap \n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle \n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700246e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in full data files\n",
    "gene_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3794d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "display(combined_data)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "# For testing set\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training RF model\n",
    "\n",
    "models = []\n",
    "n_targets = y_train.shape[1]\n",
    "\n",
    "# progress bar showing percent complete of target-level training\n",
    "pbar = tqdm(range(n_targets), desc=\"Training targets\", unit=\"target\",\n",
    "            bar_format=\"{l_bar}{bar} {n_fmt}/{total_fmt} [{percentage:3.0f}%]\")\n",
    "\n",
    "for i in pbar:\n",
    "    est = xgb.XGBRFRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_estimators=3,\n",
    "        n_jobs=-1,      # use all cores\n",
    "        verbosity=0\n",
    "    )\n",
    "    # turn off verbose printing so tqdm stays clean\n",
    "    est.fit(x_train, y_train[:, i], eval_set=[(x_val, y_val[:, i])], verbose=False)\n",
    "    models.append(est)\n",
    "    pbar.set_postfix({'target': i})\n",
    "\n",
    "predictions = np.column_stack([m.predict(x_test) for m in models])\n",
    "\n",
    "display(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54632dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving trained model \n",
    "\n",
    "with open('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/Random Forest/RF_model.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc87cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST TEST SCRIPT - ADDING IN A MULTI-OUTPUT REGRESSOR WRAPPER TO DO DEAL WITH MULTI-REGRESSION NON NATIVE TO RF MODELS \n",
    "\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from xgboost import XGBRFRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "n_targets = y_train.shape[1]\n",
    "\n",
    "# train one estimator for a given target index (must be top-level in this cell)\n",
    "def _train_target(i):\n",
    "    est = XGBRFRegressor(\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42,\n",
    "        n_estimators=100,\n",
    "        n_jobs=1,        # avoid nested parallelism inside each estimator\n",
    "        verbosity=0\n",
    "    )\n",
    "    est.fit(x_train, y_train[:, i], eval_set=[(x_val, y_val[:, i])], verbose=False)\n",
    "    return est\n",
    "\n",
    "# Prefer fork start method on mac to avoid pickling notebook-local functions\n",
    "use_process = False\n",
    "try:\n",
    "    # only set if not already set; fork avoids pickling the _train_target function\n",
    "    if mp.get_start_method(allow_none=True) != \"fork\":\n",
    "        try:\n",
    "            mp.set_start_method(\"fork\", force=True)\n",
    "        except RuntimeError:\n",
    "            # already set by another part of the session; ignore\n",
    "            pass\n",
    "    use_process = True\n",
    "except Exception:\n",
    "    use_process = False\n",
    "\n",
    "# Run parallel training with a visible tqdm progress bar.\n",
    "# If fork-based processes are available, process_map will be used (best for CPU-bound work).\n",
    "# Otherwise fall back to thread_map which works inside notebooks without pickling issues.\n",
    "chunksize = max(1, n_targets // (os.cpu_count() or 1))\n",
    "if use_process:\n",
    "    models = process_map(_train_target, list(range(n_targets)), max_workers=None, chunksize=chunksize)\n",
    "else:\n",
    "    models = thread_map(_train_target, list(range(n_targets)), max_workers=os.cpu_count() or 1, chunksize=chunksize)\n",
    "\n",
    "# quick prediction check (build matrix from list-of-estimators)\n",
    "y_pred = np.column_stack([m.predict(x_test) for m in models])\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "print(\"multi-output R^2 (uniform_average):\", r2_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "\n",
    "# Create a MultiOutputRegressor wrapper instance and attach trained estimators so it can be used like a single object\n",
    "base = XGBRFRegressor(objective='reg:squarederror', random_state=42, n_estimators=100, n_jobs=1, verbosity=0)\n",
    "multi = MultiOutputRegressor(base, n_jobs=None)   # n_jobs None because we already trained models\n",
    "# manually set attributes so multi.predict(...) will work\n",
    "multi.estimators_ = models\n",
    "multi.n_features_in_ = x_train.shape[1]\n",
    "multi.n_outputs_ = n_targets\n",
    "\n",
    "# save both the list and the single-wrapper for convenience\n",
    "with open('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/Random Forest/RF_model_list.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)\n",
    "with open('/Users/christianlangridge/Desktop/Zhang-Lab/Zhang Lab Data/Saved models/Random Forest/RF_model_multi.pkl', 'wb') as f:\n",
    "    pickle.dump(multi, f)\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
