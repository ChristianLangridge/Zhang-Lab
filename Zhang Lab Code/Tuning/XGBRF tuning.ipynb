{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c57a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap \n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle \n",
    "from sklearn.metrics import r2_score, mean_squared_error, make_scorer\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm.contrib.concurrent import process_map, thread_map\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from multiprocessing import Manager\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e1aa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in full data files\n",
    "gene_expression = pd.read_csv(('~/Zhang-Lab/Zhang Lab Data/Full data files/Geneexpression (full).tsv'), sep='\\t', header=0)\n",
    "tf_expression = pd.read_csv(('~/Zhang-Lab/Zhang Lab Data/Full data files/TF(full).tsv'), sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39e76b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training, testing and validation sets and into numpy arrays + combining dataframes\n",
    "x = tf_expression\n",
    "y = gene_expression\n",
    "\n",
    "combined_data = pd.concat([x, y], axis=1)\n",
    "\n",
    "# First split: 70% train and 30% temp (test + val)\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(\n",
    "    x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Second split: split the temp set into 20% test and 10% val (which is 2/3 and 1/3 of temp)\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_temp, y_temp, test_size=1/3, random_state=42)\n",
    "\n",
    "\n",
    "# For training set\n",
    "x_train = x_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "\n",
    "# For validation set\n",
    "x_val = x_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "\n",
    "# For testing set\n",
    "x_test = x_test.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32d4d3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3689080/2684341170.py:3: UserWarning: [01:32:26] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1764148514279/work/src/collective/../data/../common/error_msg.h:83: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  loaded = pickle.load(file)\n"
     ]
    }
   ],
   "source": [
    "# Load model in with pickle file \n",
    "with open('/home/christianl/Zhang-Lab/Zhang Lab Data/Saved models/Random Forest/RF_model.pkl', 'rb') as file:\n",
    "    loaded = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b99a492",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Evaluate model \n",
    "\n",
    " #loaded = pickle.load(file)\n",
    " #Loaded object is a list of models. n_models: 16101\n",
    " #y_pred.shape: (3187, 16101)\n",
    " #model.n_features_in_: None\n",
    " #model.n_outputs_: None\n",
    " #x_test.shape: (3187, 1198)\n",
    " #y_test.shape: (3187, 16101)\n",
    " #Multi-output R^2 (uniform_average): 0.7601639389405871\n",
    "\n",
    "\n",
    "# List of estimators (one per target gene) so build predictions matrix \n",
    "\n",
    "if isinstance(loaded, list):\n",
    "    models = loaded\n",
    "    print(\"Loaded object is a list of models. n_models:\", len(models))\n",
    "    y_pred = np.column_stack([m.predict(x_test) for m in models])  # (n_samples, n_genes)\n",
    "else:\n",
    "    model = loaded\n",
    "    print(\"Loaded object type:\", type(model))\n",
    "    # If single-output model but y_test is multi-column, this will raise -- handled later\n",
    "    y_pred = model.predict(x_test)\n",
    "\n",
    "print(\"y_pred.shape:\", y_pred.shape)\n",
    "\n",
    "# diagnostics (safe access)\n",
    "def safe_attr(obj, name):\n",
    "    return getattr(obj, name, None) if not isinstance(obj, list) else None\n",
    "\n",
    "print(\"model.n_features_in_:\", safe_attr(loaded, \"n_features_in_\"))\n",
    "print(\"model.n_outputs_:\", safe_attr(loaded, \"n_outputs_\"))\n",
    "print(\"x_test.shape:\", x_test.shape)\n",
    "print(\"y_test.shape:\", y_test.shape)\n",
    "\n",
    "# Continue with your R^2 / MSE logic expecting y_pred shape (n_samples, n_targets)\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# If y_pred is 1D, treat as single-output\n",
    "if y_pred.ndim == 1 or (y_pred.ndim == 2 and y_pred.shape[1] == 1):\n",
    "    if y_test.ndim == 2 and y_test.shape[1] > 1:\n",
    "        raise ValueError(\n",
    "            \"Model predicts a single target but y_test contains multiple targets (genes).\\n\"\n",
    "            \"Select the trained target column before splitting, e.g.:\\n\"\n",
    "            \"  target = 'GENE_NAME'\\n\"\n",
    "            \"  y = gene_expression[target]\\n\"\n",
    "            \"  then redo train_test_split and evaluation.\"\n",
    "        )\n",
    "    y_true = y_test.ravel()\n",
    "    print(\"R^2:\", r2_score(y_true, y_pred))\n",
    "    print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
    "else:\n",
    "    print(\"Multi-output R^2 (uniform_average):\", r2_score(y_test, y_pred, multioutput='uniform_average'))\n",
    "    \n",
    "    \n",
    "first = models[0]\n",
    "print(\"first estimator type:\", type(first))\n",
    "print(\"n_features_in_:\", getattr(first, \"n_features_in_\", None))\n",
    "print(\"example feature_importances_ (first 10):\", getattr(first, \"feature_importances_\", None)[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b712da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 1000)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 20)\n",
    "\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 5.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 10.0)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 1.0)\n",
    "\n",
    "    # Use the RF regressor class; note the name\n",
    "    model = xgb.XGBRFRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        learning_rate=learning_rate,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    multi_r2 = make_scorer(r2_score, multioutput=\"uniform_average\")\n",
    "\n",
    "    score = cross_val_score(\n",
    "        model, x_train, y_train, cv=5, n_jobs=-1, scoring=multi_r2\n",
    "    ).mean()\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed07cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "import xgboost as xgb\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.RandomSampler(seed=42)) # Default is random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5484b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class TqdmCallback:\n",
    "    def __init__(self, total_trials):\n",
    "        self.pbar = tqdm(total=total_trials, desc=\"Optuna Optimization\")\n",
    "    \n",
    "    def __call__(self, study, trial):\n",
    "        self.pbar.update(1)\n",
    "        self.pbar.set_postfix({\"best_r2\": f\"{study.best_value:.4f}\"})\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.pbar.close()\n",
    "\n",
    "callback = TqdmCallback(total_trials=100)\n",
    "study.optimize(objective, n_trials=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff3608",
   "metadata": {},
   "source": [
    "FULLY TEST SCRIPT FROM HERE ONWARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daa34041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BUILTIN_PREFETCH_PRESENT': True, 'CUDA_VERSION': [12, 9], 'DEBUG': False, 'GCC_VERSION': [14, 3, 0], 'GLIBC_VERSION': [2, 17], 'MM_PREFETCH_PRESENT': True, 'NCCL_VERSION': [2, 28, 9], 'THRUST_VERSION': [3, 0, 3], 'USE_CUDA': True, 'USE_DLOPEN_NCCL': False, 'USE_FEDERATED': False, 'USE_NCCL': True, 'USE_NVCOMP': False, 'USE_OPENMP': True, 'USE_RMM': False, 'libxgboost': '/home/christianl/miniconda3/envs/remote_training/lib/libxgboost.so'}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "print(xgb.build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad1c9e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-04 01:42:42,301] A new study created in memory with name: no-name-19cccd9f-19c2-4f4f-bea0-7f4d25052001\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b60043cb83452a8a0c03540fc9ed40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/optuna/study/_optimize.py:97\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(futures) >= n_jobs:\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     completed, futures = \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFIRST_COMPLETED\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     \u001b[38;5;66;03m# Raise if exception occurred in executing the completed futures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/concurrent/futures/_base.py:305\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(fs, timeout, return_when)\u001b[39m\n\u001b[32m    303\u001b[39m     waiter = _create_and_install_waiters(fs, return_when)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/threading.py:655\u001b[39m, in \u001b[36mEvent.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m     signaled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/threading.py:355\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m     gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# ---- run optimization once at top level ----\u001b[39;00m\n\u001b[32m     59\u001b[39m study = optuna.create_study(\n\u001b[32m     60\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     61\u001b[39m     sampler=optuna.samplers.RandomSampler(seed=\u001b[32m42\u001b[39m),\n\u001b[32m     62\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_gpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Optuna-level parallelism\u001b[39;49;00m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlog_progress\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# ---- now it's safe to access best_params ----\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m([t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m study.trials \u001b[38;5;28;01mif\u001b[39;00m t.state == optuna.trial.TrialState.COMPLETE]) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/optuna/study/study.py:490\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    397\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    398\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    488\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    489\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m490\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/site-packages/optuna/study/_optimize.py:82\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     79\u001b[39m time_start = datetime.datetime.now()\n\u001b[32m     80\u001b[39m futures: \u001b[38;5;28mset\u001b[39m[Future] = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=n_jobs) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m n_submitted_trials \u001b[38;5;129;01min\u001b[39;00m itertools.count():\n\u001b[32m     84\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m study._stop_flag:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/concurrent/futures/thread.py:239\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/threading.py:1149\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1146\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1149\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1151\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1152\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1153\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/remote_training/lib/python3.12/threading.py:1169\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1170\u001b[39m         lock.release()\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Manager\n",
    "import optuna\n",
    "import os\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "# ---- shared GPU queue (global, created immediately) ----\n",
    "manager = Manager()\n",
    "gpu_queue = manager.Queue()\n",
    "n_gpus = 2\n",
    "for i in range(n_gpus):\n",
    "    gpu_queue.put(i)\n",
    "\n",
    "# ---- objective: no gpu_queue argument, uses global queue ----\n",
    "def objective(trial):\n",
    "    gpu_id = gpu_queue.get()\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 200)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 8)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 0.7)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 5.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 10.0)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 1.0)\n",
    "\n",
    "    model = xgb.XGBRFRegressor(\n",
    "        device=\"cuda\",\n",
    "        tree_method=\"hist\",\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        learning_rate=learning_rate,\n",
    "        max_bin=64,\n",
    "        n_jobs=1,               # avoid nested parallelism\n",
    "    )\n",
    "\n",
    "    multi_r2 = make_scorer(r2_score, multioutput=\"uniform_average\")\n",
    "    score = cross_val_score(\n",
    "        model, x_train, y_train,\n",
    "        cv=3,\n",
    "        n_jobs=1,              # important with GPU\n",
    "        scoring=multi_r2,\n",
    "    ).mean()\n",
    "\n",
    "    gpu_queue.put(gpu_id)\n",
    "    return score\n",
    "\n",
    "# ---- callback: only logs, does NOT create a study ----\n",
    "def log_progress(study, trial):\n",
    "    print(f\"Trial {trial.number} ended with state={trial.state}, \"\n",
    "          f\"value={trial.value}, best={study.best_value}\")\n",
    "\n",
    "# ---- run optimization once at top level ----\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.RandomSampler(seed=42),\n",
    ")\n",
    "\n",
    "study.optimize(\n",
    "    objective,\n",
    "    n_trials=5,\n",
    "    n_jobs=n_gpus,            # Optuna-level parallelism\n",
    "    show_progress_bar=True,\n",
    "    callbacks=[log_progress],\n",
    ")\n",
    "\n",
    "# ---- now it's safe to access best_params ----\n",
    "if len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]) > 0:\n",
    "    best_params = study.best_params\n",
    "    print(f\"Best Hyperparameters: {best_params}\")\n",
    "else:\n",
    "    print(\"No completed trials; check logs for errors.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
